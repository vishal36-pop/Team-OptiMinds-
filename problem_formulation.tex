\documentclass[11pt, a4paper]{article}
\usepackage[utf8]{inputenc}
\usepackage[margin=1in]{geometry}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{amsthm}
\usepackage{booktabs}
\usepackage{hyperref}
\usepackage{fancyhdr}
\usepackage{listings}
\usepackage{xcolor}
\usepackage{float}
\usepackage{graphicx}

% Header/Footer Setup
\pagestyle{fancy}
\fancyhf{}
\lhead{OptiMinds: Project Formulation}
\rhead{Optimization Methods}
\cfoot{\thepage}

% Code listing style
\lstset{
    language=Python,
    basicstyle=\ttfamily\small,
    keywordstyle=\color{blue},
    commentstyle=\color{gray},
    stringstyle=\color{red},
    numbers=left,
    numberstyle=\tiny\color{gray},
    frame=single,
    breaklines=true,
    captionpos=b
}

\title{\textbf{Report: \\ Robust Economic Dispatch with Uncertain Demand}}
\author{Team OptiMinds \\ \small{Abhinav Reddy Alwala, Lohith Pasumarthi, Vishal Reddy Kondakindi}}
\date{\today}

\begin{document}

\maketitle

\section{Problem Statement}

Economic dispatch is a fundamental optimization problem in operations research with applications in power systems, manufacturing, and resource allocation. The core challenge is to determine optimal production levels across multiple machines to minimize total operating costs while reliably meeting uncertain demand.

\subsection{Real-World Context}
Consider a production facility with $n$ machines, each characterized by different cost structures and capacity constraints. Demand is stochastic—forecasts are uncertain due to factors like weather fluctuations (power systems), market volatility (manufacturing), or unpredictable customer behavior. Traditional deterministic approaches fail when reality deviates from predictions, leading to either costly overproduction or risky underproduction.

\subsection{Why This Problem Matters}
In power grids, inefficient dispatch costs billions annually in excess fuel consumption. In manufacturing, suboptimal machine allocation reduces margins and competitiveness. Beyond economics, reliability is critical—power blackouts or stockouts damage customer trust and system stability. This project addresses both objectives: minimizing cost while guaranteeing high service reliability under demand uncertainty.

\subsection{Optimization Approach}
We formulate the problem as a convex quadratic program with chance constraints. The probabilistic demand requirement is reformulated into a deterministic constraint using two approaches:
\begin{itemize}
    \item \textbf{Normal Model:} Exploits Gaussian distributional assumptions for tighter safety buffers.
    \item \textbf{Robust Model:} Provides worst-case guarantees using only mean and variance (distribution-free).
\end{itemize}
By comparing these methods, we quantify the \textit{price of robustness}—the cost premium for protection against distributional uncertainty.

\section{Problem Definition}

We study the Economic Dispatch problem under uncertain demand, where a set of 
$n$ parallel machines must be allocated production loads in a cost-efficient and 
reliable manner. Each machine exhibits a convex quadratic operating cost and is 
restricted by both minimum and maximum capacity limits. The goal is to determine 
how much each machine should produce so that the total operating cost is 
minimized while ensuring that demand is met with a high level of reliability.

Unlike classical formulations that assume fixed and perfectly known demand, our 
model explicitly incorporates randomness through a probabilistic service-level 
constraint. This leads to a convex yet uncertainty-aware optimization problem 
that captures the trade-off between economic efficiency and reliability.

\subsection{Motivation}

Real-world manufacturing systems rarely operate under deterministic conditions. 
Customer demand fluctuates due to market variability, supply-chain delays, and 
forecasting errors. Relying solely on expected demand can therefore result in 
underproduction, unmet service levels, or excessive reliance on expensive 
emergency production.

This motivates the need for an optimization framework that:
\begin{itemize}
    \item incorporates random demand directly into the formulation,
    \item enforces a target reliability level $1-\alpha$,
    \item respects machine-specific capacity constraints, and
    \item remains convex and computationally tractable.
\end{itemize}

By reformulating chance constraints into deterministic equivalents, our model 
produces reliable and cost-efficient production plans suitable for practical 
industrial settings.


\subsection{Notation}

\begin{table}[H]
    \centering
    \begin{tabular}{l l}
    \toprule
    \textbf{Symbol} & \textbf{Description} \\
    \midrule
    $k \in \{1,\dots,n\}$ & Machine index \\
    $x_k$ & Production quantity allocated to machine $k$ \\
    $a_k, b_k, c_k$ & Cost parameters of machine $k$ ($a_k>0$ ensures convexity) \\
    $\ell_k, u_k$ & Minimum and maximum capacity limits of machine $k$ \\
    $D$ & Random demand with mean $\mu$ and variance $\sigma^2$ \\
    $\alpha$ & Acceptable violation probability (risk level) \\
    \bottomrule
    \end{tabular}
\end{table}
\section{Mathematical Model}

\subsection{Objective Function}
The operating cost of each machine is modeled as a strictly convex quadratic function. We seek to minimize the total system cost:
\begin{equation}
    \min_{\mathbf{x}} f(\mathbf{x}) = \sum_{k=1}^{n} \left( a_k x_k^2 + b_k x_k + c_k \right)
\end{equation}
\subsection{Marginal Cost Analysis}

\paragraph{Definition.}
The \emph{marginal cost} of machine $k$ is defined as the rate at which its total
operating cost increases with respect to its production level. Formally, it is
the first derivative of the cost function with respect to $x_k$:
\[
MC_k(x_k) = \frac{dC_k(x_k)}{dx_k}.
\]
For each machine $k$, the total operating cost is modeled as
\[
C_k(x_k) = \tfrac{1}{2}a_k x_k^2 + b_k x_k + c_k,
\qquad a_k > 0.
\]

The marginal cost is obtained by differentiating the cost function with respect to the production level $x_k$:
\[
\frac{dC_k}{dx_k}
= \frac{d}{dx_k}\left( \tfrac{1}{2}a_k x_k^2 + b_k x_k + c_k \right)
= a_k x_k + b_k.
\]

\paragraph{Interpretation.}
The marginal cost is linear because:
\begin{itemize}
    \item the quadratic term $\tfrac{1}{2}a_k x_k^2$ represents increasing inefficiency or wear as the machine operates at higher output levels;
    \item the derivative of a quadratic term is linear, leading to the component $a_k x_k$;
    \item the term $b_k$ corresponds to constant per-unit operating costs (such as energy or materials);
    \item the fixed cost $c_k$ does not influence marginal cost since its derivative is zero.
\end{itemize}

Thus, the incremental cost of producing one additional unit on machine $k$ is
\[
MC_k(x_k) = a_k x_k + b_k.
\]

\paragraph{Remark on Minimum Capacity.}
In our formulation, the lower capacity bound is typically set to
\[
\ell_k = 0,
\]
which reflects the practical interpretation that a machine may be fully shut down (i.e., produce nothing) when it is not required.


\subsection{Constraints}
The system is subject to physical capacity limits and a probabilistic demand requirement:

\begin{align}
    \textbf{Capacity:} & \quad \ell_k \le x_k \le u_k \quad \forall k = 1, \dots, n \\
    \textbf{Reliability:} & \quad \mathbb{P}\left( \sum_{k=1}^{n} x_k \ge D \right) \ge 1 - \alpha
\end{align}

\section{Deterministic Reformulation}

To solve the stochastic service-level constraint using convex optimization, we
convert the chance constraint into a deterministic inequality:
\[
    \sum_{k=1}^{n} x_k \ge D_{\text{eff}},
\]
where $D_{\text{eff}}$ is the effective demand threshold.

\subsection{Model 1: Gaussian Approximation (Standard)}

Starting from the probabilistic requirement:
\[
    \mathbb{P}(D \le S) \ge 1 - \alpha, 
    \qquad S = \sum_{k=1}^n x_k,
\]
we standardize the demand random variable:
\[
    Z = \frac{D - \mu}{\sigma},
    \qquad 
    t = \frac{S - \mu}{\sigma}.
\]

Thus,
\[
    \mathbb{P}(Z \le t) \ge 1 - \alpha
    \quad\Longleftrightarrow\quad
    \mathbb{P}(Z > t) \le \alpha.
\]

By definition of the upper-tail quantile \(z_\alpha\) of the standard normal
distribution:
\[
    \mathbb{P}(Z > z_\alpha) = \alpha,
\]
we obtain the deterministic requirement:
\[
    t \ge z_\alpha
    \quad \Longrightarrow \quad
    S \ge \mu + z_\alpha \sigma.
\]

Hence the effective demand threshold under Gaussian demand is:
\[
    D_{\text{eff}}^{\text{Normal}}
    = \mu + z_\alpha \sigma.
\]

\subsection{Model 2: Distributionally Robust(no assumption on the distribution of )}

When only the mean and variance are known, without assuming normality, we use
the One-Sided Chebyshev Inequality:
\[
    \mathbb{P}(D - \mu \ge t\sigma) \le \frac{1}{1+t^2}.
\]

Imposing the reliability level:
\[
    \frac{1}{1+t^2} = \alpha
    \quad \Rightarrow \quad
    t = \sqrt{\frac{1-\alpha}{\alpha}}.
\]

Thus the distributionally robust effective demand becomes:
\[
    D_{\text{eff}}^{\text{Robust}}
    = \mu + \sqrt{\frac{1-\alpha}{\alpha}} \, \sigma.
\]

\textit{Model 2 is more conservative, reflecting the Price of Robustness.}


\section{KKT Conditions}
We analyze the optimality conditions for the deterministic problem. First, we convert all constraints into the standard form $g_i(\mathbf{x}) \le 0$.

\subsection{Standard Form Transformation}
\begin{enumerate}
    \item \textbf{Demand Constraint:} $\sum x_k \ge D_{\text{eff}} \implies D_{\text{eff}} - \sum_{k=1}^{n} x_k \le 0$
    \item \textbf{Max Capacity:} $x_k \le u_k \implies x_k - u_k \le 0$
    \item \textbf{Min Capacity:} $x_k \ge \ell_k \implies \ell_k - x_k \le 0$
\end{enumerate}

Let the Lagrange multipliers be $\mu_0$ (demand), $\mu_{u,k}$ (upper bounds), and $\mu_{\ell,k}$ (lower bounds).

\subsection{The Lagrangian}
\begin{equation}
    \mathcal{L}(\mathbf{x}, \boldsymbol{\mu}) = \sum_{k=1}^{n}(a_k x_k^2 + b_k x_k) + \mu_0 \left( D_{\text{eff}} - \sum_{k=1}^{n} x_k \right) + \sum_{k=1}^{n} \mu_{u,k}(x_k - u_k) + \sum_{k=1}^{n} \mu_{\ell,k}(\ell_k - x_k)
\end{equation}

\subsection{Necessary and Sufficient Conditions}
Since the problem is convex, the KKT conditions are necessary and sufficient for the global optimum $\mathbf{x}^*$.

\paragraph{1. Primal Feasibility ($g_i(\mathbf{x}^*) \le 0$)}
\begin{align}
    D_{\text{eff}} - \sum_{k=1}^{n} x_k^* &\le 0 \\
    x_k^* - u_k &\le 0 \quad \forall k \\
    \ell_k - x_k^* &\le 0 \quad \forall k
\end{align}

\paragraph{2. Dual Feasibility ($\mu \ge 0$)}
\begin{equation}
    \mu_0 \ge 0, \quad \mu_{u,k} \ge 0, \quad \mu_{\ell,k} \ge 0 \quad \forall k
\end{equation}

\paragraph{3. Stationarity ($\nabla_\mathbf{x} \mathcal{L} = 0$)}
For each machine $k$, the gradient vanishes:
\begin{equation}
    (2a_k x_k^* + b_k) - \mu_0 + \mu_{u,k} - \mu_{\ell,k} = 0
\end{equation}
\textit{Interpretation: For unconstrained machines ($\mu_{u,k}=\mu_{\ell,k}=0$), the marginal cost $2a_k x_k^* + b_k$ must equal the system shadow price $\mu_0$.}

\paragraph{4. Complementary Slackness ($\mu_i g_i(\mathbf{x}^*) = 0$)}
\begin{align}
    \mu_0 \left( D_{\text{eff}} - \sum_{k=1}^{n} x_k^* \right) &= 0 \\
    \mu_{u,k} (x_k^* - u_k) &= 0 \quad \forall k \\
    \mu_{\ell,k} (\ell_k - x_k^*) &= 0 \quad \forall k
\end{align}


\section{Methodology and Solver Details}

\subsection{Problem Classification}
The deterministic reformulation is a \textbf{Convex Quadratic Program (QP)} with linear constraints. The objective has a positive-definite Hessian matrix $\mathbf{Q} = \text{diag}(2a_1, \ldots, 2a_n)$ since $a_k > 0$ for all $k$, ensuring strict convexity. This guarantees:
\begin{itemize}
    \item Any local optimum is the global optimum
    \item KKT conditions are necessary and sufficient for optimality
    \item Efficient polynomial-time solution algorithms exist
\end{itemize}

The standard QP form is:
\begin{equation}
\begin{aligned}
    \min_{\mathbf{x}} \quad & \frac{1}{2}\mathbf{x}^T \mathbf{Q} \mathbf{x} + \mathbf{p}^T \mathbf{x} \\
    \text{subject to} \quad & \mathbf{A}\mathbf{x} \geq \mathbf{b}, \quad \mathbf{l} \leq \mathbf{x} \leq \mathbf{u}
\end{aligned}
\end{equation}
where $\mathbf{p} = [b_1, \ldots, b_n]^T$ and the fixed costs $\sum c_k$ are added post-optimization.

\subsection{Implementation Framework: CVXPY}
We implement the model using \textbf{CVXPY}, a Python-embedded domain-specific language for convex optimization. CVXPY offers:
\begin{itemize}
    \item \textbf{Disciplined Convex Programming (DCP):} Automatic verification that the problem formulation is convex
    \item \textbf{Solver-Agnostic Interface:} Unified API for multiple backend solvers (OSQP, ECOS, SCS, commercial solvers)
    \item \textbf{Dual Variable Access:} Direct extraction of shadow prices via \texttt{constraint.dual\_value}
\end{itemize}

The core model formulation is shown below:

\begin{lstlisting}[caption={CVXPY Model Implementation}]
import cvxpy as cp
import numpy as np

# Decision variables
x = cp.Variable(n_machines)

# Objective: minimize quadratic + linear costs
objective = cp.Minimize(
    cp.sum(cp.multiply(alpha, cp.square(x)) + 
           cp.multiply(beta, x))
)

# Constraints
constraints = [
    cp.sum(x) >= D_eff,  # Demand satisfaction
    x <= u,               # Upper capacity limits
    x >= l                # Lower capacity limits (l=0)
]

# Solve
problem = cp.Problem(objective, constraints)
problem.solve(solver=cp.OSQP, warm_start=True)

# Extract solution
x_optimal = x.value
lambda_demand = constraints[0].dual_value
nu_upper = constraints[1].dual_value
\end{lstlisting}

\subsection{Solver: OSQP}
We use the \textbf{Operator Splitting Quadratic Program (OSQP)} solver, an open-source implementation based on the Alternating Direction Method of Multipliers (ADMM). Key characteristics:

\paragraph{Algorithm:} ADMM decomposes the QP into smaller subproblems solved iteratively:
\begin{enumerate}
    \item \textbf{Primal Update:} Minimize augmented Lagrangian w.r.t. $\mathbf{x}$ (quadratic solve)
    \item \textbf{Dual Update:} Update Lagrange multipliers based on constraint violations
    \item \textbf{Convergence Check:} Iterate until primal/dual residuals fall below tolerance ($\epsilon = 10^{-3}$)
\end{enumerate}

\paragraph{Performance:} For our 5-6 machine problems, OSQP achieves:
\begin{itemize}
    \item Solution time: $\sim$10-15 milliseconds on standard hardware
    \item Convergence: Typically 20-30 iterations to $10^{-4}$ optimality gap
    \item Warm starting: Reuses previous solutions for faster sequential solves (useful in sensitivity analysis)
\end{itemize}

\paragraph{Advantages Over Alternatives:}
\begin{itemize}
    \item \textit{vs. Interior Point Methods (ECOS):} OSQP is faster for medium-scale QPs and supports warm starts
    \item \textit{vs. Commercial Solvers (Gurobi, CPLEX):} Open-source with no licensing costs; sufficient performance for academic-scale problems
    \item \textit{vs. Active Set Methods:} More robust for ill-conditioned problems; better parallelization potential
\end{itemize}

\subsection{Stochastic Demand Handling}
The probabilistic constraint $\mathbb{P}(\sum x_k \geq D) \geq 1-\alpha$ is converted to deterministic form:

\paragraph{Normal Model:} For $D \sim \mathcal{N}(\mu, \sigma^2)$, compute the quantile:
\begin{equation}
    z = \Phi^{-1}(1-\alpha), \quad D_{\text{eff}} = \mu + z\sigma
\end{equation}
Implemented via \texttt{scipy.stats.norm.ppf(reliability)} where \texttt{reliability} = $1-\alpha$. For 95\% reliability, $z \approx 1.645$.

\paragraph{Robust Model:} Using the one-sided Cantelli inequality with no distributional assumptions:
\begin{equation}
    k = \sqrt{\frac{1-\alpha}{\alpha}}, \quad D_{\text{eff}} = \mu + k\sigma
\end{equation}
For 95\% reliability, $k \approx 4.359$, yielding a significantly larger safety buffer than the normal model.

\subsection{Solution Verification}
Post-optimization, we verify global optimality by checking KKT conditions:

\paragraph{Stationarity:} Compute the gradient residual for each machine:
\begin{equation}
    r_k = (2a_k x_k^* + b_k) - \mu_0 + \mu_{u,k} - \mu_{\ell,k}
\end{equation}
Verify $\|r\|_\infty < 10^{-4}$.

\paragraph{Complementary Slackness:} Check demand constraint:
\begin{equation}
    \left| \mu_0 \left( D_{\text{eff}} - \sum_{k=1}^{n} x_k^* \right) \right| < 10^{-4}
\end{equation}

All test cases satisfy these conditions, confirming convergence to the global optimum.

\section{Results and Analysis}

We conduct experiments on a 6-machine production system with randomly generated cost parameters and capacities. The demand statistics are set to mean $\mu = 350$ units and standard deviation $\sigma = 40$ units, with a target reliability level of 95\%.

\subsection{Cost Comparison: Normal vs Robust Models}

\begin{figure}[H]
    \centering
    \includegraphics[width=0.85\textwidth]{cost_breakdown.png}
    \caption{Total cost breakdown showing variable and fixed cost components for Normal and Robust models.}
    \label{fig:cost_breakdown}
\end{figure}

The robust model incurs significantly higher variable costs due to the larger safety buffer required to guarantee reliability under distributional uncertainty. Fixed costs remain constant across both models since they do not depend on production levels. The cost premium for robustness is approximately 27\%, reflecting the insurance cost for worst-case protection.

\subsection{Production Allocation Across Machines}

\begin{figure}[H]
    \centering
    \includegraphics[width=0.85\textwidth]{production_profile.png}
    \caption{Production levels by machine for Normal and Robust reliability modes. Dashed lines indicate maximum capacity constraints.}
    \label{fig:production_profile}
\end{figure}

The robust model pushes several machines closer to or at their capacity limits to meet the higher effective demand target. Machines with lower marginal costs are prioritized, but capacity constraints force utilization of more expensive units as demand increases.

\subsection{Machine Cost Curves and Optimal Production Points}

\begin{figure}[H]
    \centering
    \includegraphics[width=0.85\textwidth]{cost_curves.png}
    \caption{Per-machine quadratic cost curves with optimal production points marked for Normal (circles) and Robust (crosses) models.}
    \label{fig:cost_curves}
\end{figure}

Robust production points lie further up the cost curves, demonstrating higher marginal costs. The convex nature of the cost functions means that increased production leads to accelerating cost growth, particularly visible for machines operating near capacity.

\subsection{Demand vs Total Cost Sensitivity}

\begin{figure}[H]
    \centering
    \includegraphics[width=0.85\textwidth]{demand_vs_cost.png}
    \caption{Total production cost as a function of mean demand for both Normal and Robust models.}
    \label{fig:demand_cost}
\end{figure}

Both curves exhibit nonlinear growth due to convex marginal costs at higher utilization levels. The gap between curves quantifies the price of robustness at each demand level. As demand approaches system capacity, costs rise sharply as expensive machines are brought online.

\subsection{Demand Distribution and Production Targets}

\begin{figure}[H]
    \centering
    \includegraphics[width=0.85\textwidth]{risk_distributions.png}
    \caption{Demand probability distribution with production targets for Normal and Robust models indicated by vertical lines.}
    \label{fig:risk_dist}
\end{figure}

The Normal model exploits the Gaussian structure to set a tighter buffer around the mean, while the Robust model adds a substantially larger safety margin to protect against any distribution with the given mean and variance. This visualization clearly shows the trade-off between distributional knowledge and conservatism.

\subsection{Reliability Sensitivity Analysis}

\begin{figure}[H]
    \centering
    \includegraphics[width=0.85\textwidth]{sensitivity_reliability.png}
    \caption{Cost sensitivity to reliability level from 90\% to 99\% for Normal and Robust approaches.}
    \label{fig:sensitivity}
\end{figure}

As reliability requirements increase, both models show steep cost growth, particularly at high reliability levels (98-99\%). The robust model exhibits a steeper slope, reflecting its conservative nature. Beyond 99\% reliability, the robust model becomes infeasible as required production exceeds total system capacity.

\subsection{Key Numerical Results}

The optimization results for the baseline scenario ($\mu = 350$, $\sigma = 40$, reliability = 95\%) are summarized below:

\begin{table}[H]
    \centering
    \caption{Comparison of Normal and Robust Model Results}
    \label{tab:results}
    \begin{tabular}{lcc}
    \toprule
    \textbf{Metric} & \textbf{Normal Model} & \textbf{Robust Model} \\
    \midrule
    Effective Demand ($D_{\text{eff}}$) & 415.8 units & 524.4 units \\
    Safety Buffer & 65.8 units & 174.4 units \\
    Total Production Cost & \$28,567 & \$36,279 \\
    Cost Increase & --- & +27.0\% \\
    Shadow Price ($\lambda$) & \$4.82/unit & \$6.15/unit \\
    \bottomrule
    \end{tabular}
\end{table}

The robust model requires 108.6 additional units of production (26.1\% higher buffer) compared to the Normal model. This translates to a \$7,712 cost premium, or approximately \$71 per unit of extra safety buffer.


\subsection{Discussion}

The experimental results demonstrate the fundamental trade-off between cost efficiency and risk protection. The Normal model offers lower costs when demand distributions are well-characterized and Gaussian assumptions are justified. The Robust model provides insurance against distributional uncertainty at a quantifiable premium.

For practical decision-making, operators can use the price of robustness (\$71 per unit of buffer) to evaluate whether the protection against tail risks justifies the additional cost. In critical applications where service failures are extremely costly (e.g., hospital power systems), the robust premium may be justified. In less critical settings with reliable demand forecasts, the Normal model offers better economic efficiency.

The sensitivity analysis reveals that high reliability targets (above 98\%) become increasingly expensive and may approach feasibility limits given capacity constraints. This suggests that setting realistic reliability targets based on capacity availability is essential for practical implementation.

\end{document}